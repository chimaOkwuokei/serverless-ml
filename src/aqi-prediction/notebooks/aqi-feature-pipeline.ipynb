{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2kLrOh-bpGy"
   },
   "source": [
    "# Iris Flower - Feature Pipeline\n",
    "\n",
    "In this notebook we will, \n",
    "\n",
    "1. Run in either \"Backfill\" or \"Normal\" operation. \n",
    "2. IF *BACKFILL==True*, we will load our DataFrame with data from the iris.csv file \n",
    "\n",
    "   ELSE *BACKFILL==False*, we will load our DataFrame with one synthetic Iris Flower sample \n",
    "3. Write our DataFrame to a Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hopsworks in c:\\users\\hp\\anaconda3\\lib\\site-packages (4.1.4)\n",
      "Requirement already satisfied: pyhumps==1.6.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from hopsworks) (1.6.1)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\anaconda3\\lib\\site-packages (from hopsworks) (2.31.0)\n",
      "Requirement already satisfied: furl in c:\\users\\hp\\anaconda3\\lib\\site-packages (from hopsworks) (2.1.3)\n",
      "Requirement already satisfied: boto3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from hopsworks) (1.35.87)\n",
      "Requirement already satisfied: pandas<2.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from hopsworks) (2.1.4)\n",
      "Requirement already satisfied: pyjks in c:\\users\\hp\\anaconda3\\lib\\site-packages (from hopsworks) (20.0.0)\n",
      "Requirement already satisfied: mock in c:\\users\\hp\\anaconda3\\lib\\site-packages (from hopsworks) (5.1.0)\n",
      "Requirement already satisfied: avro==1.11.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from hopsworks) (1.11.3)\n",
      "Requirement already satisfied: sqlalchemy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from hopsworks) (2.0.25)\n",
      "Requirement already satisfied: PyMySQL[rsa] in c:\\users\\hp\\anaconda3\\lib\\site-packages (from hopsworks) (1.1.1)\n",
      "Requirement already satisfied: tzlocal in c:\\users\\hp\\anaconda3\\lib\\site-packages (from hopsworks) (2.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hp\\anaconda3\\lib\\site-packages (from hopsworks) (2023.10.0)\n",
      "Requirement already satisfied: retrying in c:\\users\\hp\\anaconda3\\lib\\site-packages (from hopsworks) (1.3.4)\n",
      "Requirement already satisfied: hopsworks_aiomysql==0.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from hopsworks_aiomysql[sa]==0.2.1->hopsworks) (0.2.1)\n",
      "Requirement already satisfied: opensearch-py<=2.4.2,>=1.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from hopsworks) (2.4.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\anaconda3\\lib\\site-packages (from hopsworks) (4.65.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.49.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from hopsworks) (1.62.1)\n",
      "Requirement already satisfied: protobuf<5.0.0,>=4.25.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from hopsworks) (4.25.5)\n",
      "Requirement already satisfied: urllib3>=1.26.18 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from opensearch-py<=2.4.2,>=1.1.0->hopsworks) (2.0.7)\n",
      "Requirement already satisfied: six in c:\\users\\hp\\anaconda3\\lib\\site-packages (from opensearch-py<=2.4.2,>=1.1.0->hopsworks) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\hp\\anaconda3\\lib\\site-packages (from opensearch-py<=2.4.2,>=1.1.0->hopsworks) (2.8.2)\n",
      "Requirement already satisfied: certifi>=2022.12.07 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from opensearch-py<=2.4.2,>=1.1.0->hopsworks) (2024.12.14)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas<2.2.0->hopsworks) (1.26.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas<2.2.0->hopsworks) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas<2.2.0->hopsworks) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->hopsworks) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->hopsworks) (3.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sqlalchemy->hopsworks) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sqlalchemy->hopsworks) (3.0.1)\n",
      "Requirement already satisfied: botocore<1.36.0,>=1.35.87 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from boto3->hopsworks) (1.35.87)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from boto3->hopsworks) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from boto3->hopsworks) (0.10.4)\n",
      "Requirement already satisfied: orderedmultidict>=1.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from furl->hopsworks) (1.0.1)\n",
      "Requirement already satisfied: javaobj-py3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pyjks->hopsworks) (0.4.4)\n",
      "Requirement already satisfied: pyasn1>=0.3.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pyjks->hopsworks) (0.4.8)\n",
      "Requirement already satisfied: pyasn1-modules in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pyjks->hopsworks) (0.2.8)\n",
      "Requirement already satisfied: pycryptodomex in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pyjks->hopsworks) (3.21.0)\n",
      "Requirement already satisfied: twofish in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pyjks->hopsworks) (0.3.0)\n",
      "Requirement already satisfied: cryptography in c:\\users\\hp\\anaconda3\\lib\\site-packages (from PyMySQL[rsa]->hopsworks) (42.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tqdm->hopsworks) (0.4.6)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from cryptography->PyMySQL[rsa]->hopsworks) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\hp\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography->PyMySQL[rsa]->hopsworks) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip install hopsworks \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set **BACKFILL=True** if you want to create features from the iris.csv file containing historical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "\n",
    "#set to true initially\n",
    "\n",
    "BACKFILL= False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic Data Functions\n",
    "\n",
    "These synthetic data functions can be used to create a DataFrame containing a single Iris Flower sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "nRmFM7vcbpHA",
    "outputId": "d920d168-9818-40c5-c292-4cf0afcbbcfd"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import uuid\n",
    "\n",
    "def generate_aqi_data_dynamic():\n",
    "    \"\"\"\n",
    "    Returns a single random AQI data row as a DataFrame, dynamically generated from the existing dataset.\n",
    "    \"\"\"\n",
    "    # Load your dataset, so it can refresh and generate new values\n",
    "    aqi_df = pd.read_csv(\"../aqi.csv\")\n",
    "    # Drop rows with any empty (NaN or None) values\n",
    "    aqi_df = aqi_df.dropna()\n",
    "    # Randomly select a row from the dataset for Country, City, lat, and lng\n",
    "    location_data = aqi_df.sample(1).iloc[0]\n",
    "\n",
    "    # Define ranges for AQI components\n",
    "    aqi_ranges = {\n",
    "        \"aqi_value\": (0, 500),\n",
    "        \"co_aqi_value\": (0, 50),\n",
    "        \"ozone_aqi_value\": (0, 200),\n",
    "        \"no2_aqi_value\": (0, 100),\n",
    "        \"pm25_aqi_value\": (0, 500),\n",
    "    }\n",
    "\n",
    "    # Generate random integer values for AQI components\n",
    "    aqi_data = {key: random.randint(int(value[0]), int(value[1])) for key, value in aqi_ranges.items()}\n",
    "\n",
    "    # Add location data\n",
    "    aqi_data[\"country\"] = location_data[\"Country\"]\n",
    "    aqi_data[\"city\"] = location_data[\"City\"]\n",
    "    aqi_data[\"lat\"] = location_data[\"lat\"]\n",
    "    aqi_data[\"lng\"] = location_data[\"lng\"]\n",
    "\n",
    "    # Generate AQI Category\n",
    "    aqi_data[\"aqi_category\"] = (\n",
    "        \"Good\" if aqi_data[\"aqi_value\"] <= 50 else\n",
    "        \"Moderate\" if aqi_data[\"aqi_value\"] <= 100 else\n",
    "        \"Unhealthy for Sensitive Groups\" if aqi_data[\"aqi_value\"] <= 150 else\n",
    "        \"Unhealthy\" if aqi_data[\"aqi_value\"] <= 200 else\n",
    "        \"Very Unhealthy\" if aqi_data[\"aqi_value\"] <= 300 else\n",
    "        \"Hazardous\" if aqi_data[\"aqi_value\"] <= 500 else\n",
    "        \"Beyond Hazardous\"\n",
    "    )\n",
    "\n",
    "\n",
    "    # Create DataFrame with the correct order and column names\n",
    "    result_df = pd.DataFrame([aqi_data], columns=[\n",
    "        \"country\", \"city\", \"aqi_value\", \"aqi_category\", \"co_aqi_value\", \n",
    "        \"ozone_aqi_value\", \"no2_aqi_value\", \"pm25_aqi_value\", \"lat\", \"lng\"\n",
    "    ])\n",
    "    \n",
    "    # Ensure correct data types\n",
    "    result_df = result_df.astype({\n",
    "        'country': 'string', \n",
    "        'city': 'string', \n",
    "        'aqi_value': 'int64', \n",
    "        'aqi_category': 'string', \n",
    "        'co_aqi_value': 'int64', \n",
    "        'ozone_aqi_value': 'int64', \n",
    "        'no2_aqi_value': 'int64', \n",
    "        'pm25_aqi_value': 'int64', \n",
    "        'lat': 'float64', \n",
    "        'lng': 'float64', \n",
    "    })\n",
    "\n",
    "    return result_df\n",
    "\n",
    "def get_random_aqi_values():\n",
    "    \"\"\"\n",
    "    Returns a DataFrame containing random AQI values using the existing dataset for location data.\n",
    "    \"\"\"\n",
    "    return generate_aqi_data_dynamic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backfill or create new synthetic input data\n",
    "\n",
    "You can run this pipeline in either *backfill* or *synthetic-data* mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>aqi_value</th>\n",
       "      <th>aqi_category</th>\n",
       "      <th>co_aqi_value</th>\n",
       "      <th>ozone_aqi_value</th>\n",
       "      <th>no2_aqi_value</th>\n",
       "      <th>pm25_aqi_value</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Italy</td>\n",
       "      <td>Massarosa</td>\n",
       "      <td>303</td>\n",
       "      <td>Hazardous</td>\n",
       "      <td>16</td>\n",
       "      <td>123</td>\n",
       "      <td>58</td>\n",
       "      <td>200</td>\n",
       "      <td>43.8667</td>\n",
       "      <td>10.3333</td>\n",
       "      <td>cee2bf5f-9542-4aff-bbea-13ee87634eab</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country       city  aqi_value aqi_category  co_aqi_value  ozone_aqi_value  \\\n",
       "0   Italy  Massarosa        303    Hazardous            16              123   \n",
       "\n",
       "   no2_aqi_value  pm25_aqi_value      lat      lng  \\\n",
       "0             58             200  43.8667  10.3333   \n",
       "\n",
       "                                   uuid  \n",
       "0  cee2bf5f-9542-4aff-bbea-13ee87634eab  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import uuid\n",
    "import pandas as pd\n",
    "\n",
    "if BACKFILL == True:\n",
    "    aqi_df = pd.read_csv(\"../aqi.csv\")\n",
    "    # Example list of columns to drop\n",
    "    columns_to_drop = ['CO AQI Category', 'Ozone AQI Category', 'NO2 AQI Category', 'PM2.5 AQI Category']\n",
    "\n",
    "    # Drop all category columns except 'aqicategory'\n",
    "    aqi_df = aqi_df.drop(columns=[col for col in columns_to_drop if col in aqi_df.columns])\n",
    "else:\n",
    "    aqi_df = get_random_aqi_values()\n",
    "   \n",
    "# Add UUID to each row\n",
    "aqi_df[\"uuid\"] = [str(uuid.uuid4()) for _ in range(len(aqi_df))]\n",
    "\n",
    "# Drop rows with any empty (NaN or None) values\n",
    "aqi_df = aqi_df.dropna()\n",
    "# Refactoring column names\n",
    "aqi_df.columns = [col.lower().replace(' ', '_').replace('.', '') for col in aqi_df.columns]\n",
    "aqi_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authenticate with Hopsworks using your API Key\n",
    "\n",
    "Hopsworks will prompt you to paste in your API key and provide you with a link to find your API key if you have not stored it securely already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-03 00:53:45,254 INFO: Initializing external client\n",
      "2025-01-03 00:53:45,256 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-01-03 00:53:48,614 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1207459\n"
     ]
    }
   ],
   "source": [
    "#GJG5iRl8457zOwDh.DgZqNKTOsoidXdslZaeeNzVRrWwcPos5a0VjR3Hw7ONynMMdDo39Wm9YAP232zhl\n",
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and write to a feature group - primary keys\n",
    "\n",
    "To prevent duplicate entries, Hopsworks requires that each DataFame has a *primary_key*. \n",
    "A *primary_key* is one or more columns that uniquely identify the row. Here, we assume\n",
    "that each Iris flower has a unique combination of (\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\")\n",
    "feature values. If you randomly generate a sample that already exists in the feature group, the insert operation will fail.\n",
    "\n",
    "The *feature group* will create its online schema using the schema of the Pandas DataFame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 1/1 | Elapsed Time: 00:02 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: aqi_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1207459/jobs/named/aqi_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('aqi_1_offline_fg_materialization', 'SPARK'), None)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aqi_fg = fs.get_or_create_feature_group(name=\"aqi\",\n",
    "                                  version=1,\n",
    "                                  primary_key=[\"uuid\"],\n",
    "                                  description=\"Air Quality Prediction dataset project\"\n",
    "                                 )\n",
    "aqi_fg.insert(aqi_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iris_fg.read()\n",
    "# # \tsepal_length\tsepal_width\tpetal_length\tpetal_width\tvariety\tuuid\n",
    "# # 0\t5.732203\t2.366797\t3.115597\t1.155345\tVersicolor\te5452a04-75a6-45c4-95cf-be4807f537d9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
